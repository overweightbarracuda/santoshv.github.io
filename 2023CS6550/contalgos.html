<!DOCTYPE html>
<link rel="stylesheet" href="style.css">
<html>
<body>
<div>
<h2>CS6550/8803: Continuous Algorithms: Optimization and Sampling</h2>
<h4>Spring 2023. MW: 2-3:15pm, Weber SST III, L1</h4>
<h4>Santosh Vempala, Klaus 2222, Office hour: Wed 3:30-4:30pm.<br>
TAs: Max Dabagia, Jai Moondra, Disha Aravind.</h4>

<p>The design of algorithms is traditionally a discrete endeavor. However, many advances have come from a 
continuous viewpoint. Typically, a continuous process, deterministic or randomized is designed (or shown) to have 
desirable properties, such as approaching an optimal solution or a desired distribution, and an algorithm is 
derived from this by appropriate discretization. We will use this viewpoint to develop several general techniques and build up to the state-of-the-art in polynomial algorithms for optimization and sampling.
<ul>
<li>Reduction</li>
<li>Elimination</li>
<li>Conditioning</li>
<li>Geometrization</li>
<li>Expansion</li>
<li>Sparsification</li>
<li>Acceleration</li>
<li>Decomposition</li>
<li>Discretization</li>
</ul>


<p><b>Prerequisite</b>: basic knowledge of algorithms, probability, linear algebra.</p><br>

<b><a href="https://github.com/YinTat/optimizationbook/blob/main/main.pdf">Textbook</a></b> (in progress, with Yin Tat Lee)<br></p><br>

<p><b>Grading</b>:<br>
HW: Biweekly HW, including one longer HW towards the end. You are encouraged to collaborate on HW, but must write your own solutions. Submit via gradescope (link on canvas).<br>
6550: HW, one mid-term exam. Send comments on textbook each week via this <a href="https://docs.google.com/forms/d/e/1FAIpQLScN4UUO8Oy2JZTg9oJbEnQb0WNQtUCJiZVqgTs4eOoiCaVwjw/viewform?vc=0&c=0&w=1&flr=0">form</a>.<br>
8803: No exam. HW; comment on textbook each week.<br>
Bonus: suggesting simpler proofs, exercises, figures.<br>
</p>
<br>




<b>Schedule</b> (tentative):
<ol>
<li> Introduction<br>
Jan 9. Course overview. Chap 1. <a href="https://www.dropbox.com/s/movp7v21z0cdepz/Jan9.pdf?dl=0">Notes</a>. <a href="https://www.dropbox.com/s/bbmib25lmyard3g/hw1.pdf?dl=0">HW1</a> (due Tue, Jan 17th)<br> 
Jan 11. Gradient descent. Chap 2. <a href="https://www.dropbox.com/s/8hrgasn9evr73m6/Jan11.pdf?dl=0">Notes</a>.<br>
Jan 16. MLK holiday.<br>
Jan 18. Gradient-based Sampling: Langevin dynamics. Chap 8. <a href="https://www.dropbox.com/s/n71g2tkmheytuph/Jan18.pdf?dl=0">Notes</a>. <br>

<li>Elimination<br>

Jan 25. Cutting Plane Method: Ellipsoid Algorithm. Chap 3. <a href="https://www.dropbox.com/s/7aubbqw7mf80qf4/Jan25.pdf?dl=0">Notes</a>. <br>
Jan 30. Cutting Plane Method: Center of Gravity. Chap 3. <a href="https://www.dropbox.com/s/z9rqpfxpe5sy8xr/Jan30.pdf?dl=0">Notes</a>. <br>
Feb 1. CPM: Computing the Volume. Chap 9. <a href="https://www.dropbox.com/s/ec0hpjg84r1a1ck/Feb1.pdf?dl=0">Notes</a>.<br>

<li>Reduction<br>

Feb 6. Oracles and Duality. Chap 4. <a href="https://www.dropbox.com/s/wupcik6vbqsg3d2/Feb6.pdf?dl=0">Notes</a><br>
Feb 8,13. Duality and Duality. Chap 4. <a href="https://www.dropbox.com/s/utdnqtrkfb4zoxr/Feb8.pdf?dl=0">Notes</a><br>
Feb 15. Optimization from Membership. Chap 4. <a href="https://www.dropbox.com/s/o6u2q46fxo0f2ds/Feb13.pdf?dl=0">Notes</a><br>


<li>Geometrization I: Euclidean<br>

Feb 20. Markov chains and conductance. <a href="https://www.dropbox.com/s/20299ftulatvkat/Feb20.pdf?dl=0">Notes</a>.<br>
Feb 22. Sampling convex bodies: the Ball Walk. <a href="https://www.dropbox.com/s/x6uaicviszztyz4/Feb22.pdf?dl=0">Notes</a>.<br>
Feb 27. Local conductance and Warm starts. <a href="https://www.dropbox.com/s/634yied3jg63akn/Feb27.pdf?dl=0">Notes</a>.<br>
Mar 1. Euclidean Isoperimetry and the Localization Lemma. <a href="https://www.dropbox.com/s/frtmh5d27zg87sd/Mar1.pdf?dl=0">Notes</a>.<br>
Mar 6. A Rapidly Mixing Markov Chain for Convex Bodies. <a href="https://www.dropbox.com/s/4n6hznosx5zskxf/Mar6.pdf?dl=0">Notes</a>.<br>
Mar 8. Sampling and Volume in Polynomial Time. <a href="https://www.dropbox.com/s/lrdyzfclap16lmd/Mar8.pdf?dl=0">Notes</a>.<br>

<li>Geometrization II: Non-Euclidean<br>

Mar 13. The Central Path Method.<a href="https://www.dropbox.com/s/bz0e3dvux18or8f/Mar13.pdf?dl=0">Notes</a>.<br>

</ol>
<p>
Mar 15. <b>Midterm</b>.

<!--

Feb 13, 15.
Feb 20, 22.
Feb 27.
Mar 1.
Mar 6, 8.
Mar 13, 15.
Mar 20, 22. Spring break.
Mar 27, 29.
Apr 3, 5.
Apr 10, 12.
Apr 17, 19.
Apr 24.

Jan 23. Ball method; lower bounds. <a href="L5Jan23.pdf">Notes</a><br>

<li>Reduction<br>

Jan 28. Duality (LP duality, SDP duality, ...). <a href="L6Jan28.pdf">Notes</a><br> 
Jan 30, 4. Equivalences (Optimization, Membership, Separation; Gradient, Evaluation). <a href="L7Jan30.pdf">Notes</a><br>

<li>Geometrization I<br>

Feb 4. Mirror Descent. <a href="L9Feb4.pdf">Notes</a><br>
Feb 6. Frank-Wolfe. <a href="L10Feb6.pdf">Notes</a><br>
Feb 11. Newton method<br>
Feb 13, 18. Interior Point Method for LP.<a href="L13Feb20.pdf">Notes</a><br>
Feb 20, 25. Self-concordance and IPM for convex optimization.<br>

<li>Sparsification<br>

Mar 3. Regression and subspace embeddings.<a href="L15Mar2.pdf">Notes</a><br>
Mar 5. Matrix approximation.<br>

<li> Acceleration<br> 

Mar 10. Linear Regression and Chebychev Polynomials. <a href="L16Mar10.pdf">Notes</a><br>
Mar 12. Conjugate Gradient. <a href="L17Mar12.pdf">Notes</a><br>

Mar 17,19 (Spring break)

<li>Sampling<br>

Mar 24. Langevin Dynamics and SDE.<br>
Mar 26. Conductance and Convergence<br>

<li>Geometrization II<br>

Apr 7. Mixing of the ball walk, Isotropy.<br>
Apr 9. Isoperimetry, KLS<br>
Apr 14. Volume Computation <br>  
Apr 16. Gaussian Cooling <br>

Additional topics: (Riemannian) HMC, ODE, Complex analysis.<br>

--!>



</p>
</div>
</body>
