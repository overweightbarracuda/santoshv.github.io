<!DOCTYPE html>
<link rel="stylesheet" href="style.css">
<html>
<body>
<div>
<h2>CS6550/8803: Continuous Algorithms: Optimization and Sampling</h2>
<h4>Spring 2023. MW: 2-3:15pm, Weber SST III, L1</h4>
<h4>Santosh Vempala, Klaus 2222, Office hour: Wed 3:30-4:30pm.<br>
TAs: Max Dabagia, Jai Moondra, Disha Aravind.</h4>

<p>The design of algorithms is traditionally a discrete endeavor. However, many advances have come from a 
continuous viewpoint. Typically, a continuous process, deterministic or randomized is designed (or shown) to have 
desirable properties, such as approaching an optimal solution or a desired distribution, and an algorithm is 
derived from this by appropriate discretization. We will use this viewpoint to develop several general techniques and build up to the state-of-the-art in polynomial algorithms for optimization and sampling.
<ul>
<li>Reduction</li>
<li>Elimination</li>
<li>Conditioning</li>
<li>Geometrization</li>
<li>Expansion</li>
<li>Sparsification</li>
<li>Acceleration</li>
<li>Decomposition</li>
<li>Discretization</li>
</ul>


<p><b>Prerequisite</b>: basic knowledge of algorithms, probability, linear algebra.</p><br>

<b><a href="https://github.com/YinTat/optimizationbook/blob/main/main.pdf">Textbook</a></b> (in progress, with Yin Tat Lee)<br></p><br>

<p><b>Grading</b>:<br>
HW: Biweekly HW, including one longer HW towards the end. You are encouraged to collaborate on HW, but must write your own solutions. Submit via gradescope (link on canvas).<br>
6550: HW, one mid-term exam. Send comments on textbook each week via this <a href="https://docs.google.com/forms/d/e/1FAIpQLScN4UUO8Oy2JZTg9oJbEnQb0WNQtUCJiZVqgTs4eOoiCaVwjw/viewform?vc=0&c=0&w=1&flr=0">form</a>.<br>
8803: No exam. HW; comment on textbook each week.<br>
Bonus: suggesting simpler proofs, exercises, figures.<br>
</p>
<br>




<b>Schedule</b> (tentative):
<ol>
<li> Introduction<br>
Jan 9. Course overview. Chap 1. <a href="https://www.dropbox.com/s/movp7v21z0cdepz/Jan9.pdf?dl=0">Notes</a>. <a href="https://www.dropbox.com/s/bbmib25lmyard3g/hw1.pdf?dl=0">HW1</a> (due Tue, Jan 17th)<br> 
Jan 11. Gradient descent. Chap 2. <a href="https://www.dropbox.com/s/8hrgasn9evr73m6/Jan11.pdf?dl=0">Notes</a>.<br>
Jan 16. MLK holiday.<br>
Jan 18. Gradient-based Sampling: Langevin dynamics. Chap 8. <a href="https://www.dropbox.com/s/n71g2tkmheytuph/Jan18.pdf?dl=0">Notes</a>. <br>

<li>Elimination<br>

Jan 25. Cutting Plane Method: Ellipsoid Algorithm. Chap 3. <a href="https://www.dropbox.com/s/7aubbqw7mf80qf4/Jan25.pdf?dl=0">Notes</a>. <br>
Jan 30. Cutting Plane Method: Center of Gravity. Chap 3. <a href="https://www.dropbox.com/s/z9rqpfxpe5sy8xr/Jan30.pdf?dl=0">Notes</a>. <br>
Feb 1. CPM: Computing the Volume. Chap 9. <a href="https://www.dropbox.com/s/ec0hpjg84r1a1ck/Feb1.pdf?dl=0">Notes</a>.<br>

<li>Reduction<br>

Feb 6. Oracles and Duality. Chap 4. <a href="https://www.dropbox.com/s/wupcik6vbqsg3d2/Feb6.pdf?dl=0">Notes</a><br>
Feb 8,13. Duality and Duality. Chap 4. <a href="https://www.dropbox.com/s/utdnqtrkfb4zoxr/Feb8.pdf?dl=0">Notes</a><br>
Feb 15. Optimization from Membership. Chap 4. <a href="https://www.dropbox.com/s/o6u2q46fxo0f2ds/Feb13.pdf?dl=0">Notes</a><br>


<li>Geometrization I: Euclidean<br>

Feb 20. Markov chains and conductance. <a href="https://www.dropbox.com/s/20299ftulatvkat/Feb20.pdf?dl=0">Notes</a>.<br>
Feb 22. Sampling convex bodies: the Ball Walk. <a href="https://www.dropbox.com/s/x6uaicviszztyz4/Feb22.pdf?dl=0">Notes</a>.<br>
Feb 27. Local conductance and Warm starts. <a href="https://www.dropbox.com/s/634yied3jg63akn/Feb27.pdf?dl=0">Notes</a>.<br>
Mar 1. Euclidean Isoperimetry and the Localization Lemma. <a href="https://www.dropbox.com/s/frtmh5d27zg87sd/Mar1.pdf?dl=0">Notes</a>.<br>
Mar 6. A Rapidly Mixing Markov Chain for Convex Bodies. <a href="https://www.dropbox.com/s/4n6hznosx5zskxf/Mar6.pdf?dl=0">Notes</a>.<br>
Mar 8. Sampling and Volume in Polynomial Time. <a href="https://www.dropbox.com/s/lrdyzfclap16lmd/Mar8.pdf?dl=0">Notes</a>.<br>


<li>Geometrization II: Non-Euclidean<br>

Mar 13. The Central Path Method. <a href="https://www.dropbox.com/s/bz0e3dvux18or8f/Mar13.pdf?dl=0">Notes</a>.<br>
Mar 27. The Newton Method. <a href = "https://www.dropbox.com/s/ue7w7x4pb54agsv/Mar27.pdf">Notes</a>.<br> 
Mar 29, Apr 3. Interior-Point Algorithms. <a href="https://www.dropbox.com/s/mijvonm2ug9kas6/Mar29.pdf?dl=0">Notes</a>. <a href="https://www.dropbox.com/s/uli6sib25tk5fno/Apr4.pdf?dl=0">Summary</a>.<br>  
Apr 5. Norms, Metrics, Hessians. <a href="https://www.dropbox.com/s/l6w0kh17r4j9v65/Apr5.pdf?dl=0">Notes</a>.<br>
Apr 10, 12. Affine-Invariant Sampling. <a href="https://www.dropbox.com/s/hwcci0goh6qhc3x/Apr10.pdf?dl=0">Dikin</a>, <a href="https://www.dropbox.com/s/zh22i0of0ik9tf0/Apr12.pdf?dl=0">(R)HMC and beyond</a>.<br>
Apr 17, 19.<br> 
Apr 24.<br>
</ol>
<p>
Mar 15. <b>Midterm</b>.<br>

Mar 27. The Newton Method. <a href = "https://www.dropbox.com/s/ue7w7x4pb54agsv/Mar27.pdf">Notes</a>.<br> 
Mar 29, Apr 3. Interior-Point Algorithms. <a href="https://www.dropbox.com/s/mijvonm2ug9kas6/Mar29.pdf?dl=0">Notes</a>. <a href="https://www.dropbox.com/s/uli6sib25tk5fno/Apr4.pdf?dl=0">Summary</a>.<br>  
Apr 5. Norms, Metrics, Hessians. <a href="https://www.dropbox.com/s/l6w0kh17r4j9v65/Apr5.pdf?dl=0">Notes</a>.<br>
Apr 10, 12. Affine-Invariant Sampling. <a href="https://www.dropbox.com/s/hwcci0goh6qhc3x/Apr10.pdf?dl=0">Dikin</a>, <a href="https://www.dropbox.com/s/zh22i0of0ik9tf0/Apr12.pdf?dl=0">(R)HMC and beyond</a>.<br>
Apr 17, 19. Simulated Annealing for Volume Computation.<br> 

<li>Discretization<br>
Apr 24. Lattices and Basis Reduction. <a href="">Notes</a>.<br>
</ol>


</p>
</div>
</body>



