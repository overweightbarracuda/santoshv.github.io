<!DOCTYPE html>
<link rel="stylesheet" href="style.css">
<html>
<body>
<div>
<h2>Continuous Algorithms: Optimization and Sampling</h2>
<h3>Santosh Vempala</h3>
<h3>TA: He Jia</h3>
<h4>Spring 2020. TR: 9:30-10:45. Arch.(East) 207.</h4>
<p>The design of algorithms is traditionally a discrete endeavor. However, many advances have come from a 
continuous viewpoint. Typically, a continuous process, deterministic or randomized is designed (or shown) to have 
desirable properties, such as approaching an optimal solution or a desired distribution, and an algorithm is 
derived from this by appropriate discretization. We will use this viewpoint to develop several general techniques and build up to the state-of-the-art in polynomial algorithms for optimization and sampling.
<ul>
<li>Reduction</li>
<li>Elimination</li>
<li>Conditioning</li>
<li>Geometrization</li>
<li>Expansion</li>
<li>Sparsification</li>
<li>Acceleration</li>
<li>Decomposition</li>
<li>Discretization</li>
</ul>
</div>
</body>


This will be a more detailed and self-contained version of a <a href="https://santoshv.github.io/contalgos.html">previous edition</a>.<br>
The course is offered at UW by <a href="http://yintat.com/teaching/cse535-winter20/">Yin Tat Lee</a></p>



<p><b>Prerequisite</b>: basic knowledge of algorithms, probability, linear algebra.</p>
<b><a href="https://www.dropbox.com/s/s3upwyegevioo56/main.pdf?dl=0">Book</a></b> (in progress)<br></p>



  <b>Schedule</b> (tentative):<br>



<ol>



<li> Introduction<br>



Jan 7. Course overview. <br> 



Jan 9. Gradient descent.







<li>Elimination<br>



Jan 14. Ellipsoid/CoG/Cutting Plane.<br>



Jan 16. Bolas y Parabolas







<li>Reduction<br>



Jan 21, 23. Duality (LP duality, SDP duality, ...) and Equivalences (Optimization, Membership, Separation; OPT, Integration->Sampling; Maxflow, Bipartite Matching)







<li>Geometrization I<br>



Jan 28. Lower bounds <br>



Jan 30. Mirror Descent <br>



Feb 4. Frank-Wolfe <bR>



Feb 6. Newton method<br>



Feb 11. Interior Point Method<br>



Feb 13. IPM for LP.







<li>Sparsification<br>



Feb 18. Regression and subspace embeddings.<br>



Feb 20. Matrix approximation.<br>



Feb 25. Coordinate Descent.<br>



Feb 27. Stochastic Gradient Descent.







<li> Acceleration<br> 



Mar 3. Conjugate Gradient and Chebychev Expansion.<br>



Mar 5. Accelerated Gradient Descent.







<li> Decomposition<br>



Mar 10. <br>



Mar 12. <br>







Mar 17,19 (Spring break)<br>







<li>Sampling<br>



Mar 24. Langevin Dynamics and SDE.<br>



Mar 26. Conductance, Ball walk<br>







<li>Geometrization II<br>



Apr 7. Mixing of ball walk, Isoperimetry, Isotropy.<br>



Apr 9. Hit-and-Run, Dikin walk<br>



Apr 14. (Riemannian) HMC<br>



Apr 16. ODE. Complex analysis.<br>



</ol>











</p>



</div>



</body>
